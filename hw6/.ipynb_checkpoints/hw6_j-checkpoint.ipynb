{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from patsy import dmatrices\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import datasets, svm\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "JobSurvey = pd.read_csv('2016 Stack Overflow Survey Responses.csv')\n",
    "\n",
    "JobSurvey = JobSurvey.dropna()\n",
    "\n",
    "n = JobSurvey.shape[0]\n",
    "p = JobSurvey.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the headers\n",
    "headers = list(JobSurvey)\n",
    "\n",
    "obj_JobSurvey = JobSurvey.select_dtypes(include=['object']).copy()\n",
    "\n",
    "for job in obj_JobSurvey:\n",
    "    JobSurvey[job] = obj_JobSurvey[job].astype('category')\n",
    "    JobSurvey[job] = JobSurvey[job].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df1 = JobSurvey[ JobSurvey.occupation == 'Business intelligence or data warehousing expert' ]\n",
    "# df2 = JobSurvey[ JobSurvey.occupation == 'Data scientist' ]\n",
    "# df3 = JobSurvey[ JobSurvey.occupation == 'Developer with a statistics or mathematics background' ]\n",
    "# df4 = JobSurvey[ JobSurvey.occupation == 'Machine learning developer' ]\n",
    "\n",
    "# frames = [df1, df2, df3, df4]\n",
    "# DataScience = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[ 12302.77151667]]\n",
      "Mean squared error: 2472154328.66\n",
      "Variance score: -252245.40\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABxBQQYAR1CQAcAR/w9h+mlLom2C1AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1321b198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55955</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55956</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55957</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55958</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55960</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55962</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55965</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55966</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55968</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55969</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55970</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55971</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55975</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55979</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55980</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55981</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55983</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55984</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55985</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55986</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55987</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55988</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55990</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55991</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55994</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55997</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55998</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55999</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56000</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15591 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age_range\n",
       "187            4\n",
       "196            0\n",
       "197            0\n",
       "199            2\n",
       "200            2\n",
       "203            0\n",
       "204            0\n",
       "205            3\n",
       "208            3\n",
       "211            3\n",
       "213            1\n",
       "216            3\n",
       "217            1\n",
       "222            5\n",
       "228            2\n",
       "232            0\n",
       "233            1\n",
       "235            7\n",
       "236            4\n",
       "242            1\n",
       "245            1\n",
       "248            1\n",
       "254            2\n",
       "256            5\n",
       "259            2\n",
       "260            3\n",
       "263            1\n",
       "264            4\n",
       "266            0\n",
       "270            4\n",
       "...          ...\n",
       "55955          1\n",
       "55956          3\n",
       "55957          4\n",
       "55958          0\n",
       "55960          2\n",
       "55962          1\n",
       "55965          2\n",
       "55966          2\n",
       "55968          1\n",
       "55969          1\n",
       "55970          2\n",
       "55971          1\n",
       "55975          2\n",
       "55979          1\n",
       "55980          1\n",
       "55981          2\n",
       "55983          1\n",
       "55984          3\n",
       "55985          2\n",
       "55986          3\n",
       "55987          2\n",
       "55988          2\n",
       "55990          2\n",
       "55991          2\n",
       "55994          4\n",
       "55996          0\n",
       "55997          5\n",
       "55998          3\n",
       "55999          2\n",
       "56000          1\n",
       "\n",
       "[15591 rows x 1 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use only one feature\n",
    "JobSurvey_X = JobSurvey[['age_range']]\n",
    "JobSurvey_y = JobSurvey[['salary_midpoint']]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "sample_size = math.floor(0.75 * n)   ###### Use 75% of the data for the training set\n",
    "\n",
    "JobSurvey_X_train = JobSurvey_X[:sample_size]\n",
    "JobSurvey_X_test = JobSurvey_X[sample_size:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "JobSurvey_y_train = JobSurvey_y[:sample_size]\n",
    "JobSurvey_y_test =JobSurvey_y[sample_size:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(JobSurvey_X_train, JobSurvey_y_train)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.mean((regr.predict(JobSurvey_X_test) - JobSurvey_y_test) ** 2))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(diabetes_X_test, diabetes_y_test))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(JobSurvey_X_test, JobSurvey_y_test,  color='black')\n",
    "plt.plot(JobSurvey_X_test, regr.predict(JobSurvey_X_test), color='blue',\n",
    "         linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()\n",
    "JobSurvey[['age_range']][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Meta Stack Overflow Post'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-3f381c142a3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[1;31m# Train the model using the training sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataScience_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataScience_y_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[1;31m# The coefficients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jennifer.macdonald\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 512\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jennifer.macdonald\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32mC:\\Users\\jennifer.macdonald\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Meta Stack Overflow Post'"
     ]
    }
   ],
   "source": [
    "# Use only one feature\n",
    "DataScience_X = DataScience[['collector']]\n",
    "DataScience_y = DataScience[['salary_midpoint']]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "n = DataScience_X.shape[0]\n",
    "sample_size = math.floor(0.75 * n)   ###### Use 75% of the data for the training set\n",
    "\n",
    "DataScience_X_train = DataScience_X[:sample_size]\n",
    "DataScience_X_test = DataScience_X[sample_size:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "DataScience_y_train = DataScience_y[:sample_size]\n",
    "DataScience_y_test = DataScience_y[sample_size:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(DataScience_X_train, DataScience_y_train)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.mean((regr.predict(DataScience_X_test) - DataScience_y_test) ** 2))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(diabetes_X_test, diabetes_y_test))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(DataScience_X_test, DataScience_y_test,  color='black')\n",
    "plt.plot(DataScience_X_test, regr.predict(DataScience_X_test), color='blue',\n",
    "         linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
